{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aJtpNWf0BJ1"
      },
      "source": [
        "<center><h1>Law Keywords Predictor</h1></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82lTfU7q0BJ4"
      },
      "source": [
        "<h2>Loading Modules</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3vyolBX0BJ5",
        "outputId": "1bf5fbec-4c1c-4839-846b-83789e06c839"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import scipy.optimize as opt\n",
        "from sklearn import metrics \n",
        "from sklearn.metrics import f1_score, jaccard_similarity_score, classification_report, confusion_matrix\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "np.random.seed(0)\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import glorot_uniform\n",
        "np.random.seed(1)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggP1mYYR0BJ7"
      },
      "source": [
        "<h2>Loading Data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "116-4tze0BJ7",
        "outputId": "8c52ea90-8b67-492e-f8de-f7e8e73caaa0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kurian Joseph, J.</td>\n",
              "      <td>Cause of Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1. Leave granted in Special Leave Petition (Ci...</td>\n",
              "      <td>Cause of Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2. Around 46.93 acres of Land was acquired by ...</td>\n",
              "      <td>Cause of Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3. Learned Counsel for the Appellants submitte...</td>\n",
              "      <td>Cause of Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4. Shri Sanjay Kumar Tyagi, learned Additional...</td>\n",
              "      <td>Cause of Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5. Learned Counsel appearing for the Appellant...</td>\n",
              "      <td>Cause of Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6. Prior to amendment Act 68 of 1984, the amou...</td>\n",
              "      <td>Cause of Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Section 25. Rules as to amount of compensation-</td>\n",
              "      <td>Cause of Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(1) When the applicant has made a claim to com...</td>\n",
              "      <td>Cause of Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(2) When the applicant has refused to make suc...</td>\n",
              "      <td>Cause of Action</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                File         Keywords\n",
              "0                                  Kurian Joseph, J.  Cause of Action\n",
              "1  1. Leave granted in Special Leave Petition (Ci...  Cause of Action\n",
              "2  2. Around 46.93 acres of Land was acquired by ...  Cause of Action\n",
              "3  3. Learned Counsel for the Appellants submitte...  Cause of Action\n",
              "4  4. Shri Sanjay Kumar Tyagi, learned Additional...  Cause of Action\n",
              "5  5. Learned Counsel appearing for the Appellant...  Cause of Action\n",
              "6  6. Prior to amendment Act 68 of 1984, the amou...  Cause of Action\n",
              "7    Section 25. Rules as to amount of compensation-  Cause of Action\n",
              "8  (1) When the applicant has made a claim to com...  Cause of Action\n",
              "9  (2) When the applicant has refused to make suc...  Cause of Action"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lst1=[]\n",
        "lst2=[]\n",
        "for i in range(80):\n",
        "    name1=\"C:\\\\Users\\\\Aayush Singhal\\\\Downloads\\\\Projects\\\\8. Law Keywords Prediction\\\\Dataset\\\\Data\\\\Train_tags\\\\case\"+str(i)+\".txt\"\n",
        "    name2=\"C:\\\\Users\\\\Aayush Singhal\\\\Downloads\\\\Projects\\\\8. Law Keywords Prediction\\\\Dataset\\\\Data\\\\Train_docs\\\\case_\"+str(i)+\"_statement.txt\"\n",
        "    f1=open(name1,\"r\")\n",
        "    f2=open(name2,\"r\")\n",
        "    y=f1.read()\n",
        "    for x in f2:\n",
        "        x=x.replace(\"\\n\",'')\n",
        "        if len(x)>0:\n",
        "            lst2.append(x.replace('\\n',''))\n",
        "            lst1.append(y)\n",
        "f1.close()\n",
        "f2.close()\n",
        "text=pd.DataFrame(data={\"File\":lst2,\"Keywords\":lst1})\n",
        "text.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVVJIK6t0BJ8",
        "outputId": "c814f973-67f6-4485-e638-3f7f03779a2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "File        object\n",
              "Keywords    object\n",
              "dtype: object"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mAjyd2y0BJ9",
        "outputId": "444641ee-646f-4639-acef-99bedd105571"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3961</td>\n",
              "      <td>3961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3855</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>1. Leave granted.</td>\n",
              "      <td>Absence, Accommodation, Amendment, Appeal, App...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>17</td>\n",
              "      <td>313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     File                                           Keywords\n",
              "count                3961                                               3961\n",
              "unique               3855                                                 79\n",
              "top     1. Leave granted.  Absence, Accommodation, Amendment, Appeal, App...\n",
              "freq                   17                                                313"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUkZ1T4x0BJ-"
      },
      "source": [
        "<h2>Preprocessing Data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "956_vUmU0BJ-",
        "outputId": "f136aed8-7af4-4ab0-8e14-2b972fe33636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 3961\n",
            "Columns: 2\n"
          ]
        }
      ],
      "source": [
        "print(\"Rows: {}\\nColumns: {}\".format(text.shape[0],text.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIKrBrTm0BJ_",
        "outputId": "5400e224-9c06-4528-d9db-37e96257ce07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "File        0\n",
              "Keywords    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjsMtM4I0BKA",
        "outputId": "df61f540-12ce-4719-a24c-41347458afb9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEzCAYAAAD0AO6PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYZ0lEQVR4nO3df7BndX3f8eeLXSG2UX4puLOLA5bNRNSElA3YJFBGfrgmxqUjxGWoLlPoihPG/vijxVpCBjtTmHYGa2ptL4ouJAoMtLCp2nWBYGmTkF2UoGgo6yYjV3bwx24o9Qdkue/+cc/q8fq99+5+P2e9sN/ng/nMPefz+Zzz/Ry43Pe8P59zzjdVhSRJLQ5b6gFIkl78DCaSpGYGE0lSM4OJJKmZwUSS1MxgIklqZjCRpBewJGuTPJZkR5KrRrSfleQLSfYmuXBO24Ykj3dlQ6/+tCRf6s75oSRpHafBRJJeoJIsAz4MvAU4Bbg4ySlzun0duBT45JxjjwGuAc4ATgeuSXJ01/wRYCOwuitrW8dqMJGkF67TgR1VtbOqngNuBdb1O1TVX1XVI8DMnGPfDGytqt1VtQfYCqxNsgJ4eVX9Sc0+tX4zcEHrQA0mkvTCtRJ4orc/3dW1HLuy2x7nnPNavlDj9lUX+K4VSYesNdN3Na8V7PM339451t/Lw1/5d97N7JTTPlNVNdVtjxrf/n7OfMe2nHNeCwYTSdLB1QWOqXmap4ETevurgCf389TTwNlzjr2/q1815jnn5TSXJA1h5vnxysK2AauTnJTkcGA9sHk/R7QFOD/J0d3C+/nAlqraBTyT5I3dXVzvAu4e76J/xGAiSUOomfHKQqes2gtcyWxg+Cpwe1U9muTaJG8DSPLLSaaBi4D/kuTR7tjdwAeYDUjbgGu7OoD3AB8FdgBfAz7bevlZ6BX0rplIOpQNumay66tj/b18yYrXDjaGpeSaiSQNoBbJMg51BhNJGsKMwUSS1MrMRJLUbPE7sw5pBhNJGoKZiSSpmWsmkqRW3s0lSWpnZiJJamZmIklq5t1ckqRmZiaSpGaumUiSmk14ZuIr6CVJzcxMJGkITnNJklpVeTeXJKnVhK+ZGEwkaQhOc0mSmpmZSJKa+QS8JKmZmYkkqZlrJpKkZmYmkqRmZiaSpGYTHkx8N5ckDaDq+bHKYpKsTfJYkh1JrhrRfkSS27r2B5Oc2NVfkuThXplJcmrXdn93zn1tx7Vev5mJJA3hIGQmSZYBHwbOA6aBbUk2V9VXet0uA/ZU1clJ1gPXA++oqj8A/qA7zxuAu6vq4d5xl1TV9qHGamYiSUOomfHKwk4HdlTVzqp6DrgVWDenzzpgU7d9B3BOkszpczHwqcYrXJDBRJKGMDMzXlnYSuCJ3v50VzeyT1XtBZ4Gjp3T5x38ZDD5eDfFdfWI4HPADCaSNIQxM5MkG5Ns75WNvbOO+iNfc/YX7JPkDOB7VfXlXvslVfUG4MyuvHPMq/4h10wkaQlV1RQwNU/zNHBCb38V8OQ8faaTLAeOBHb32tczJyupqm90P59J8klmp9NuHvcawMxEkoZxcKa5tgGrk5yU5HBmA8PmOX02Axu67QuB+6qqAJIcBlzE7FoLXd3yJK/otl8CvBX4Mo3MTCRpCAfhCfiq2pvkSmALsAy4qaoeTXItsL2qNgMfA25JsoPZjGR97xRnAdNVtbNXdwSwpQsky4B7gBtbx2owkaQhHKSHFqvqM8Bn5tT9Tm/7B8xmH6OOvR9445y67wKnDT1Og4kkDWHCn4A3mEjSEHzRoySpmZmJJKmZmYkkqZmZiSSpmZmJJKmZmYkkqZnBRJLUrOa+f3GyGEwkaQhmJpKkZgYTSVIz7+aSJDWb8MzE7zORJDUzM5GkIXg3lySp2YRPcxlMJGkIBhNJUjPv5pIktaoZ10wkSa2c5pIkNXOaS5LUzGkuSVIzp7kkSc0MJpKkZhP+BLzv5pKkIczMjFcWkWRtkseS7Ehy1Yj2I5Lc1rU/mOTErv7EJN9P8nBX/nPvmNOSfKk75kNJ0nr5BhNJGsJMjVcWkGQZ8GHgLcApwMVJTpnT7TJgT1WdDNwAXN9r+1pVndqVK3r1HwE2Aqu7srbp2jGYSNIwama8srDTgR1VtbOqngNuBdbN6bMO2NRt3wGcs1CmkWQF8PKq+pOqKuBm4IJxLrnPYCJJQzgImQmwEniitz/d1Y3sU1V7gaeBY7u2k5J8Mcnnk5zZ6z+9yDkPmAvwkjSAGvNuriQbmZ1y2meqqqb2NY/6qLmnmKfPLuDVVfWdJKcBdyV53X6e84AZTCRpCXWBY2qe5mnghN7+KuDJefpMJ1kOHAns7qawnu0+46EkXwN+ruu/apFzHjCnuSRpCAdnmmsbsDrJSUkOB9YDm+f02Qxs6LYvBO6rqkryym4BnySvYXahfWdV7QKeSfLGbm3lXcDdrZdvZiJJQzgI7+aqqr1JrgS2AMuAm6rq0STXAturajPwMeCWJDuA3cwGHICzgGuT7AWeB66oqt1d23uATwAvBT7blSYGE0kawkF6N1dVfQb4zJy63+lt/wC4aMRxdwJ3znPO7cDrhxynwUSShuDrVCRJzXxrsCSpmd9nIklqZmYiSWo17kOLhwqDiSQNwcxEktTMYCJJauYCvCSpmZmJJKlVGUwkSc0MJpKkZt4aLElqZmYiSWo24cHEL8eSJDUzM5GkAcx+S+7kMphI0hAmfJrLYCJJQzCYSJJa+dCiJKmdwUSS1Gyyn1k0mEjSEJzmkiS1M5hIkpo5zSVJajXp01y+TkWShjAzZllEkrVJHkuyI8lVI9qPSHJb1/5gkhO7+vOSPJTkS93PN/WOub8758NdOa7p2jEzkaRBHIzMJMky4MPAecA0sC3J5qr6Sq/bZcCeqjo5yXrgeuAdwLeB36yqJ5O8HtgCrOwdd0lVbR9qrGYmkjSEg5OZnA7sqKqdVfUccCuwbk6fdcCmbvsO4JwkqaovVtWTXf2jwM8kOWLs61uEwUSSBlAz45VFrASe6O1P8+PZxY/1qaq9wNPAsXP6vB34YlU926v7eDfFdXWSHODl/gSDiSQNYczMJMnGJNt7ZWPvrKP+yM+dT1uwT5LXMTv19e5e+yVV9QbgzK68c7+vcx6umUjSAPYjyxh9XNUUMDVP8zRwQm9/FfDkPH2mkywHjgR2AyRZBfw34F1V9bXeZ36j+/lMkk8yO51283hXMMvMRJJeuLYBq5OclORwYD2weU6fzcCGbvtC4L6qqiRHAZ8G3ldV/3tf5yTLk7yi234J8Fbgy60DNTORpCEchIcWq2pvkiuZvRNrGXBTVT2a5Fpge1VtBj4G3JJkB7MZyfru8CuBk4Grk1zd1Z0PfBfY0gWSZcA9wI2tY81C3w62fdUFk/0UjqRD2prpu5oXnvf51nl/f6y/l6/c+vnBxrCUzEwkaQDjrpkcKgwmkjQAg4kkqV0dErNVYzOYSNIAzEwkSc1qxsxEktTIzESS1KxcM5EktTIzkSQ1c81EktRsgZeJTASDiSQNwMxEktTMYCJJauY0lySp2aRnJn45liSpmZmJJA3AhxYlSc18aFGS1GzGzESS1MppLklSs0m/m8tgIkkD8DkTSVIzMxNJUjMX4CVJzVyAlyQ1m/Q1E1+nIkkDmKmMVRaTZG2Sx5LsSHLViPYjktzWtT+Y5MRe2/u6+seSvHl/zzkOg4kkDaAqY5WFJFkGfBh4C3AKcHGSU+Z0uwzYU1UnAzcA13fHngKsB14HrAX+U5Jl+3nOA2YwkaQBVI1XFnE6sKOqdlbVc8CtwLo5fdYBm7rtO4BzkqSrv7Wqnq2qvwR2dOfbn3MeMIOJJA3gIE1zrQSe6O1Pd3Uj+1TVXuBp4NgFjt2fcx4wg4kkDWDcaa4kG5Ns75WNvdOOijZz85n5+hxofRPv5pKkAYz7nElVTQFT8zRPAyf09lcBT87TZzrJcuBIYPcixy52zgNmZiJJL1zbgNVJTkpyOLML6pvn9NkMbOi2LwTuq6rq6td3d3udBKwG/mw/z3nAzEwkaQAH4zGTqtqb5EpgC7AMuKmqHk1yLbC9qjYDHwNuSbKD2YxkfXfso0luB74C7AV+u6qeBxh1ztaxpha4nWD7qgsm/DEcSYeyNdN3DfbY+h+vePtYfy9/Zdedh8Sj82YmkjQAX6ciSWo24d/aazCRpCHUyDtuJ4fBRJIGMDPhK8wGE0kawIyZiSSpldNckqRmLsBLkpqZmUiSmpmZSJKaGUwkSc2c5pIkNZuZ7FhiMJGkIficiSSp2YQ/AO+XY0mS2pmZSNIAvJtLktRsJq6ZSJIaTfqaicFEkgbgNJckqZnPmUiSmvmciSSpmWsmkqRmTnNJkpq5AC9Jajbp01y+TkWSBjCT8UqLJMck2Zrk8e7n0fP029D1eTzJhq7ubyX5dJK/SPJokut6/S9N8q0kD3fl8sXGYjCRpAHMjFkaXQXcW1WrgXu7/R+T5BjgGuAM4HTgml7Q+fdV9fPALwG/muQtvUNvq6pTu/LRxQZiMJGkASxRMFkHbOq2NwEXjOjzZmBrVe2uqj3AVmBtVX2vqv4IoKqeA74ArBp3IAYTSRpAZbzS6Piq2gXQ/TxuRJ+VwBO9/emu7oeSHAX8JrPZzT5vT/JIkjuSnLDYQFyAl6QBjJtlJNkIbOxVTVXVVK/9HuBVIw59//5+xIi6H94vkGQ58CngQ1W1s6v+Q+BTVfVskiuYzXretNCHGEwkaQDjBpMucEwt0H7ufG1Jnkqyoqp2JVkBfHNEt2ng7N7+KuD+3v4U8HhVfbD3md/ptd8IXL/QNYDTXJI0iBqzNNoMbOi2NwB3j+izBTg/ydHdwvv5XR1J/g1wJPBP+wd0gWmftwFfXWwgBhNJevG6DjgvyePAed0+SdYk+ShAVe0GPgBs68q1VbU7ySpmp8pOAb4w5xbg93a3C/858F7g0sUG4jSXJA1gKV6n0k1HnTOifjtweW//JuCmOX2mGb2eQlW9D3jfgYzFYCJJA/B1KpKkZgYTSVKzSX83l8FEkgbgK+glSc2c5pIkNXOaS5LUbGbCw4nBRJIG4DSXJKnZZOclBhNJGoSZiSSpmbcGS5KauQAvSWo22aHEYCJJg3DNRJLUbNKnufxyLElSMzMTSRrAZOclBhNJGoRrJpKkZpO+ZmIwkaQBTHYoMZhI0iCc5pIkNasJz00MJpI0ADMTSVIzF+AlSc0mO5T4BLwkDWKGGqu0SHJMkq1JHu9+Hj1Pvw1dn8eTbOjV35/ksSQPd+W4rv6IJLcl2ZHkwSQnLjYWg4kkDWBmzNLoKuDeqloN3Nvt/5gkxwDXAGcApwPXzAk6l1TVqV35Zld3GbCnqk4GbgCuX2wgBhNJGkCN+U+jdcCmbnsTcMGIPm8GtlbV7qraA2wF1h7Aee8Azkmy4Nd/GUwkaQBLlJkcX1W7ALqfx43osxJ4orc/3dXt8/FuiuvqXsD44TFVtRd4Gjh2oYG4AC9JAxg3y0iyEdjYq5qqqqle+z3Aq0Yc+v79/YgRdfsGe0lVfSPJy4A7gXcCNy9yzEgGE0kawLhZRhc4phZoP3e+tiRPJVlRVbuSrAC+OaLbNHB2b38VcH937m90P59J8klm11Ru7o45AZhOshw4Eti90HU4zSVJA5ipGqs02gzsuztrA3D3iD5bgPOTHN0tvJ8PbEmyPMkrAJK8BHgr8OUR570QuK9q4cGamUjSi9d1wO1JLgO+DlwEkGQNcEVVXV5Vu5N8ANjWHXNtV/e3mQ0qLwGWAfcAN3Z9PgbckmQHsxnJ+sUGYjCRpAEsxUOLVfUd4JwR9duBy3v7NwE3zenzXeC0ec77A7rAtL8MJpI0AF+nIklq5luDJUnNfGuwJKmZ01ySpGZOc0mSmjnNJUlqtsgzfYc8g4kkDcA1E0lSM6e5JEnNXICXJDVzmkuS1MwFeElSM9dMJEnNXDORJDWb9DUTv2lRktTMzESSBuACvCSp2aRPcxlMJGkALsBLkprNOM0lSWo12aHEYCJJg3DNRJLUzGAiSWrmrcGSpGaTnpn4BLwkDaDG/KdFkmOSbE3yePfz6Hn6bej6PJ5kQ1f3siQP98q3k3ywa7s0ybd6bZcvNhYzE0kawBJNc10F3FtV1yW5qtv/l/0OSY4BrgHWMHvT2UNJNlfVHuDUXr+HgP/aO/S2qrpyfwdiZiJJA5ihxiqN1gGbuu1NwAUj+rwZ2FpVu7sAshVY2++QZDVwHPDAuAMxmEjSAKpqrNLo+Kra1X3+LmYDwlwrgSd6+9NdXd/FzGYi/QG9PckjSe5IcsJiA3GaS5IGMG6WkWQjsLFXNVVVU732e4BXjTj0/fv7ESPq5g52PfDO3v4fAp+qqmeTXMFs1vOmhT7EYCJJAxh3Mb0LHFMLtJ87X1uSp5KsqKpdSVYA3xzRbRo4u7e/Cri/d45fBJZX1UO9z/xOr/+NwPWLXIbTXJI0hJmqsUqjzcCGbnsDcPeIPluA85Mc3d3tdX5Xt8/FwKf6B3SBaZ+3AV9dbCBmJpL04nUdcHuSy4CvAxcBJFkDXFFVl1fV7iQfALZ1x1xbVbt75/gt4NfnnPe9Sd4G7AV2A5cuNpAstAC0fdUFk/0UjqRD2prpu0atJ4zldcefMdbfy0efenCwMSwlMxNJGoCvoJckNfPLsSRJzcxMJEnNzEwkSc3MTCRJzcxMJEnNqmaWeghLymAiSQOY9C/HMphI0gD82l5JUjMzE0lSMzMTSVIzbw2WJDXz1mBJUjOnuSRJzVyAlyQ1m/TMxK/tlSQ1MzORpAF4N5ckqdmkT3MZTCRpAC7AS5KamZlIkpq5ZiJJauYT8JKkZmYmkqRmk75m4kOLkjSAGvOfFkmOSbI1yePdz6Pn6fc/kvx1kv8+p/6kJA92x9+W5PCu/ohuf0fXfuJiYzGYSNIAqmqs0ugq4N6qWg3c2+2P8u+Ad46ovx64oTt+D3BZV38ZsKeqTgZu6PotyGAiSQNYomCyDtjUbW8CLphnbPcCz/TrkgR4E3DHiOP7570DOKfrPy+DiSQNoMYsjY6vql0A3c/jDuDYY4G/rqq93f40sLLbXgk80Z13L/B0139eCy7Ar5m+a8FIpNGSbKyqqaUehyaHv3NLb+9z3xjr72WSjcDGXtVU/79lknuAV4049P3jfF7/o0fU1X60jeTdXAfHRsD/sfXT5O/ci1QXOOb9b1dV587XluSpJCuqaleSFcA3D+Cjvw0clWR5l32sAp7s2qaBE4DpJMuBI4HdC53MaS5JevHaDGzotjcAd+/vgTW7YPNHwIUjju+f90LgvlpkgSeTfm/0wZBke1WtWepxaHL4OzeZkhwL3A68Gvg6cFFV7U6yBriiqi7v+j0A/Dzws8B3gMuqakuS1wC3AscAXwT+YVU9m+RngFuAX2I2I1lfVTsXHIvBZHjOX+unzd85LTWDiSSpmWsmkqRmBpMxJXk+ycO9cmKSNUk+1LVfmuQ/LvU49cKQ5P/1tn+9e33Fq5dyTH1J7u/m2aWxeGvw+L5fVafOqfsrYPsSjEUvEknOAX4POL+qvr5EY1jee1BNGoSZyYCSnD33RWpd/SuT3JlkW1d+dSnGp6WV5EzgRuA3quprXd1P/G4kOazLXF7Z9Tmse+He8Ul2ZtZRSWaSnNX1eSDJyd2L/+5K8kiSP03yC1377yaZSvI54OYkL01ya9fvNuClXb9lST6R5MtJvpTkny3Fvyu9+JiZjO+lSR7utv+yqv7BAn3/A7MvU/tf3dTGFuC1B32EeiE5gtl7+M+uqr/o1f/E70ZVvTbJ7wOXAB8EzgX+vKqeSvJ/gFOAk4CHgDOTPAisqqodSX4P+GJVXZDkTcDNwL4M+jTg16rq+0n+OfC9qvqFLuB8oetzKrCyql4PkOSog/ZvRIcUg8n4Rk1zzedc4JTee9JenuRlVfXMAsfo0PI3wB8z+zbWf9KrH/m7AdzEbPD5IPCPgI937Q8AZzEbTP4t8I+BzwPbuvZfA94OUFX3JTk2yZFd2+aq+n63fRbwoa7fI0ke6ep3Aq/pgtKngc+1X7omgdNcPx2HAX+vqk7tykoDycSZAX4L+OUk/6pXP/J3o6qeAJ7qsoszgM92/R8AzgROBz4DHAWcDfzPrn2hdyp9d576H1VU7QF+Ebgf+G3gowdykZpcBpOfjs8BV+7bSbK/GY0OIVX1PeCtwCVJ9n1vxEK/Gx8Ffh+4vaqe7+oeBH4FmKmqHwAPA+9mNsjAbFC5pDvX2cC3q+r/jhhOv9/rgX1rK68ADquqO4Grgb/bcMmaIAaTn473Amu6xc6vAFcs9YC0NKpqN7AW+NdJ1rHw78ZmZl9/8fHe8c8y+2rwP+2qHgBeBnyp2//dfecDruNH71ea6yPAz3b9/gXwZ139SuD+bj3wE8D7xr5YTRSfgJdeoLrnPm6oqjOXeizSYlyAl16AklwFvIduKkp6oTMzkSQ1c81EktTMYCJJamYwkSQ1M5hIkpoZTCRJzQwmkqRm/x8DFfSZcYIF0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 504x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.rcParams['figure.figsize']=7,5\n",
        "sns.heatmap(text.isnull(),yticklabels=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRztW7Bf0BKA"
      },
      "source": [
        "<p>The dataset has no null values.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gh4v4zV0BKB"
      },
      "source": [
        "<h3>Encoding labels into numbers</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFw7nYHc0BKB"
      },
      "outputs": [],
      "source": [
        "Keyword_codes=text.groupby(['Keywords']).ngroup()\n",
        "Keywords=text['Keywords'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU3VTddV0BKB"
      },
      "outputs": [],
      "source": [
        "IDs=dict()\n",
        "for i,j in zip(Keywords,Keyword_codes.unique()):\n",
        "    IDs.update({j:i})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3Z02mXO0BKB"
      },
      "source": [
        "<h2>1. Using Machine Learning</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6THMZPSc0BKC"
      },
      "source": [
        "<h3>Lemmatizing and Cleaning Sentences</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4Or4hIm0BKC"
      },
      "outputs": [],
      "source": [
        "def word_clean(cases):\n",
        "    processedText=[]\n",
        "    wordLemm=WordNetLemmatizer()\n",
        "    urlPattern=r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "    userPattern='@[^\\s]+'\n",
        "    alphaPattern=\"[^a-zA-Z0-9]\"\n",
        "    sequencePattern=r\"(.)\\1\\1+\"\n",
        "    seqReplacePattern=r\"\\1\\1\"   \n",
        "    for case in cases:\n",
        "        case=case.lower()\n",
        "        case=re.sub(urlPattern,' URL',case)\n",
        "        case=re.sub(userPattern,' USER',case)        \n",
        "        case=re.sub(alphaPattern, \" \",case)\n",
        "        case=re.sub(sequencePattern, seqReplacePattern,case)\n",
        "        casewords = ''\n",
        "        for word in case.split():\n",
        "            if len(word)>1:\n",
        "                word = wordLemm.lemmatize(word)\n",
        "                casewords += (word+' ')            \n",
        "        processedText.append(casewords)\n",
        "    return processedText\n",
        "processedText=word_clean(text['File'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfZamOz70BKC",
        "outputId": "bd7a2a78-f398-47a8-b20d-3c0c816fced6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kurian joseph</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>leave granted in special leave petition civil ...</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>around 46 93 acre of land wa acquired by the r...</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>learned counsel for the appellant submitted th...</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shri sanjay kumar tyagi learned additional adv...</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                File  Labels\n",
              "0                                     kurian joseph       67\n",
              "1  leave granted in special leave petition civil ...      67\n",
              "2  around 46 93 acre of land wa acquired by the r...      67\n",
              "3  learned counsel for the appellant submitted th...      67\n",
              "4  shri sanjay kumar tyagi learned additional adv...      67"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.DataFrame(data={\"File\":processedText,\"Labels\":Keyword_codes})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRlOIE3k0BKD",
        "outputId": "fbae558b-7713-4497-c7e5-559d6a2370ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "File      object\n",
              "Labels     int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62oP5bKX0BKD",
        "outputId": "b72ba332-0aec-4d76-ad3b-004b440bc4fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([67,  2, 77, 68, 24, 41, 70, 15, 22, 34, 13, 14, 75, 76, 55, 40, 30,\n",
              "        4, 10, 74, 56, 51, 69, 32,  3, 33, 78, 31, 23, 73, 43, 20, 19,  1,\n",
              "       62,  0, 16, 57, 65, 47, 44, 59, 46, 26, 21, 36, 11, 25, 35, 64, 63,\n",
              "       52, 42, 38, 28,  6, 60, 54, 12, 18, 29, 45, 61, 39, 17, 71, 49, 72,\n",
              "        7, 53, 48, 27, 66,  8, 37,  9, 58, 50,  5], dtype=int64)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Labels'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P38lkeck0BKD",
        "outputId": "fade604c-a6c8-4019-9fec-b7a9b02ec7c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df['Labels'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1HWqC290BKD"
      },
      "source": [
        "<h3>Converting to vectors</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JMX4Hjt0BKE",
        "outputId": "b073eb0c-0a90-4f94-87d8-8f4407377c69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0,\n",
              "                max_features=500000, min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
              "                strip_accents=None, sublinear_tf=False,\n",
              "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
              "                vocabulary=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectoriser=TfidfVectorizer(ngram_range=(1,2),max_features=500000)\n",
        "vectoriser.fit(df['File'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5Hu0Q4W0BKE"
      },
      "outputs": [],
      "source": [
        "X=vectoriser.transform(df['File'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvrasaqE0BKE"
      },
      "outputs": [],
      "source": [
        "def model_Evaluate(model):\n",
        "    y_pred=model.predict(X)\n",
        "    print(classification_report(df['Labels'],y_pred))\n",
        "    cf_matrix=confusion_matrix(df['Labels'],y_pred)\n",
        "    print(cf_matrix)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsjkB9AA0BKE"
      },
      "source": [
        "<h2>Data Modelling</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjZU80zy0BKF"
      },
      "source": [
        "<h3>1. Bernoulli Naive Bayes</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK7xZGkE0BKF",
        "outputId": "1759c54b-3771-4064-e4df-1aefc9fbb6c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        38\n",
            "           1       0.97      0.91      0.94        92\n",
            "           2       1.00      0.69      0.82        13\n",
            "           3       0.93      0.94      0.94       100\n",
            "           4       0.92      0.98      0.95        48\n",
            "           5       1.00      0.85      0.92        33\n",
            "           6       1.00      0.82      0.90       313\n",
            "           7       1.00      0.95      0.98        66\n",
            "           8       1.00      0.82      0.90        11\n",
            "           9       0.46      0.98      0.63       153\n",
            "          10       0.97      0.83      0.90        42\n",
            "          11       1.00      0.79      0.88        29\n",
            "          12       0.78      0.95      0.86        65\n",
            "          13       1.00      0.90      0.95        40\n",
            "          14       1.00      0.82      0.90        68\n",
            "          15       1.00      0.80      0.89        45\n",
            "          16       1.00      0.87      0.93        23\n",
            "          17       1.00      0.95      0.97        79\n",
            "          18       1.00      0.31      0.47        13\n",
            "          19       1.00      0.78      0.88        32\n",
            "          20       0.97      0.88      0.92        40\n",
            "          21       0.99      0.91      0.95       101\n",
            "          22       0.98      0.82      0.89        65\n",
            "          23       1.00      0.33      0.50         3\n",
            "          24       1.00      1.00      1.00        20\n",
            "          25       1.00      0.72      0.84        50\n",
            "          26       1.00      0.92      0.96        24\n",
            "          27       0.98      0.91      0.94       191\n",
            "          28       0.96      0.94      0.95       139\n",
            "          29       1.00      0.89      0.94        28\n",
            "          30       1.00      0.55      0.71        31\n",
            "          31       1.00      1.00      1.00         1\n",
            "          32       1.00      0.71      0.83         7\n",
            "          33       0.95      0.88      0.91        59\n",
            "          34       1.00      0.84      0.91        31\n",
            "          35       1.00      0.84      0.91       100\n",
            "          36       1.00      0.67      0.80        12\n",
            "          37       1.00      0.89      0.94         9\n",
            "          38       1.00      0.86      0.93        81\n",
            "          39       1.00      1.00      1.00        10\n",
            "          40       1.00      0.75      0.86         8\n",
            "          41       0.92      0.97      0.94        35\n",
            "          42       1.00      0.29      0.44         7\n",
            "          43       1.00      0.86      0.92         7\n",
            "          44       1.00      0.85      0.92        13\n",
            "          45       1.00      0.91      0.95       100\n",
            "          46       1.00      0.80      0.89        25\n",
            "          47       1.00      0.60      0.75        15\n",
            "          48       1.00      0.20      0.33         5\n",
            "          49       1.00      0.93      0.96        40\n",
            "          50       1.00      0.77      0.87        44\n",
            "          51       1.00      0.64      0.78        11\n",
            "          52       1.00      0.62      0.77         8\n",
            "          53       1.00      0.95      0.97        40\n",
            "          54       1.00      0.79      0.88        24\n",
            "          55       1.00      0.56      0.71         9\n",
            "          56       1.00      0.71      0.83         7\n",
            "          57       0.51      0.96      0.67       102\n",
            "          58       1.00      0.84      0.91        25\n",
            "          59       1.00      0.78      0.88        23\n",
            "          60       0.98      0.91      0.94        97\n",
            "          61       1.00      0.33      0.50         6\n",
            "          62       0.58      1.00      0.73       251\n",
            "          63       1.00      0.57      0.73         7\n",
            "          64       0.95      0.98      0.96        83\n",
            "          65       1.00      0.90      0.95        20\n",
            "          66       1.00      0.85      0.92        74\n",
            "          67       0.95      0.83      0.89        24\n",
            "          68       1.00      0.75      0.86         4\n",
            "          69       1.00      0.84      0.91       107\n",
            "          70       1.00      0.80      0.89        71\n",
            "          71       1.00      0.68      0.81        76\n",
            "          72       1.00      0.90      0.95        51\n",
            "          73       1.00      0.65      0.79        17\n",
            "          74       1.00      0.76      0.87        38\n",
            "          75       0.78      0.86      0.82        29\n",
            "          76       1.00      0.77      0.87        30\n",
            "          77       1.00      0.84      0.91        19\n",
            "          78       0.96      0.73      0.83       104\n",
            "\n",
            "    accuracy                           0.87      3961\n",
            "   macro avg       0.97      0.80      0.86      3961\n",
            "weighted avg       0.92      0.87      0.88      3961\n",
            "\n",
            "[[36  0  0 ...  0  0  0]\n",
            " [ 0 84  0 ...  0  0  0]\n",
            " [ 1  0  9 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 23  0  0]\n",
            " [ 0  0  0 ...  0 16  0]\n",
            " [ 0  0  0 ...  0  0 76]]\n"
          ]
        }
      ],
      "source": [
        "BNBmodel=BernoulliNB(alpha=0.01)\n",
        "BNBmodel.fit(X,df['Labels'])\n",
        "Y1=model_Evaluate(BNBmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qgIEJGC0BKF"
      },
      "source": [
        "<h3>Accuracy Metrics</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlETcDTY0BKF",
        "outputId": "88ac1f1d-4b26-4c9c-94b2-5d45c9418c0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "J1=jaccard_similarity_score(df['Labels'],Y1)\n",
        "FS1=f1_score(df['Labels'],Y1,average='weighted')\n",
        "Acc1=metrics.accuracy_score(df['Labels'],Y1)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT062rZ90BKF"
      },
      "source": [
        "<h3>2. Support Vector Machine</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W-LZg8e0BKF",
        "outputId": "9559150b-f764-41dc-c7a1-1825033ecbd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        38\n",
            "           1       0.97      0.98      0.97        92\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       1.00      0.98      0.99       100\n",
            "           4       1.00      1.00      1.00        48\n",
            "           5       1.00      1.00      1.00        33\n",
            "           6       1.00      0.99      0.99       313\n",
            "           7       1.00      0.97      0.98        66\n",
            "           8       1.00      0.91      0.95        11\n",
            "           9       1.00      0.97      0.99       153\n",
            "          10       1.00      0.88      0.94        42\n",
            "          11       1.00      0.97      0.98        29\n",
            "          12       0.98      0.97      0.98        65\n",
            "          13       1.00      0.93      0.96        40\n",
            "          14       0.96      1.00      0.98        68\n",
            "          15       1.00      0.93      0.97        45\n",
            "          16       1.00      0.96      0.98        23\n",
            "          17       0.99      1.00      0.99        79\n",
            "          18       0.79      0.85      0.81        13\n",
            "          19       1.00      0.84      0.92        32\n",
            "          20       1.00      0.97      0.99        40\n",
            "          21       1.00      0.98      0.99       101\n",
            "          22       0.98      0.97      0.98        65\n",
            "          23       1.00      1.00      1.00         3\n",
            "          24       1.00      1.00      1.00        20\n",
            "          25       1.00      0.88      0.94        50\n",
            "          26       1.00      0.92      0.96        24\n",
            "          27       0.97      0.98      0.97       191\n",
            "          28       0.98      0.99      0.98       139\n",
            "          29       0.96      0.96      0.96        28\n",
            "          30       1.00      0.94      0.97        31\n",
            "          31       1.00      1.00      1.00         1\n",
            "          32       1.00      0.71      0.83         7\n",
            "          33       0.95      1.00      0.98        59\n",
            "          34       1.00      0.87      0.93        31\n",
            "          35       1.00      0.92      0.96       100\n",
            "          36       1.00      0.92      0.96        12\n",
            "          37       1.00      1.00      1.00         9\n",
            "          38       1.00      0.96      0.98        81\n",
            "          39       1.00      1.00      1.00        10\n",
            "          40       1.00      0.75      0.86         8\n",
            "          41       1.00      0.97      0.99        35\n",
            "          42       0.24      0.86      0.38         7\n",
            "          43       1.00      1.00      1.00         7\n",
            "          44       1.00      1.00      1.00        13\n",
            "          45       0.98      0.99      0.99       100\n",
            "          46       0.92      0.96      0.94        25\n",
            "          47       1.00      0.87      0.93        15\n",
            "          48       0.60      0.60      0.60         5\n",
            "          49       1.00      0.97      0.99        40\n",
            "          50       1.00      0.98      0.99        44\n",
            "          51       1.00      0.82      0.90        11\n",
            "          52       0.78      0.88      0.82         8\n",
            "          53       1.00      1.00      1.00        40\n",
            "          54       1.00      1.00      1.00        24\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       0.88      1.00      0.93         7\n",
            "          57       0.86      0.96      0.91       102\n",
            "          58       1.00      0.96      0.98        25\n",
            "          59       1.00      0.96      0.98        23\n",
            "          60       0.99      0.99      0.99        97\n",
            "          61       1.00      0.67      0.80         6\n",
            "          62       0.87      1.00      0.93       251\n",
            "          63       0.54      1.00      0.70         7\n",
            "          64       0.95      1.00      0.98        83\n",
            "          65       1.00      0.95      0.97        20\n",
            "          66       0.95      0.99      0.97        74\n",
            "          67       1.00      0.96      0.98        24\n",
            "          68       1.00      1.00      1.00         4\n",
            "          69       0.98      0.99      0.99       107\n",
            "          70       1.00      1.00      1.00        71\n",
            "          71       0.98      0.79      0.88        76\n",
            "          72       1.00      0.96      0.98        51\n",
            "          73       0.93      0.82      0.87        17\n",
            "          74       1.00      1.00      1.00        38\n",
            "          75       1.00      0.93      0.96        29\n",
            "          76       1.00      1.00      1.00        30\n",
            "          77       1.00      1.00      1.00        19\n",
            "          78       0.99      0.99      0.99       104\n",
            "\n",
            "    accuracy                           0.97      3961\n",
            "   macro avg       0.96      0.94      0.95      3961\n",
            "weighted avg       0.97      0.97      0.97      3961\n",
            "\n",
            "[[ 37   0   0 ...   0   0   0]\n",
            " [  0  90   0 ...   0   0   0]\n",
            " [  0   0  13 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...  30   0   0]\n",
            " [  0   0   0 ...   0  19   0]\n",
            " [  0   0   0 ...   0   0 103]]\n"
          ]
        }
      ],
      "source": [
        "SVCmodel=LinearSVC()\n",
        "SVCmodel.fit(X,df['Labels'])\n",
        "Y2=model_Evaluate(SVCmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pna6MNxf0BKG"
      },
      "source": [
        "<h3>Accuracy Metrics</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAx1x0cb0BKG",
        "outputId": "4e5382d7-b104-470e-993b-af42de1964bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "J2=jaccard_similarity_score(df['Labels'],Y2)\n",
        "FS2=f1_score(df['Labels'],Y2,average='weighted')\n",
        "Acc2=metrics.accuracy_score(df['Labels'],Y2)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngS_UF_-0BKG"
      },
      "source": [
        "<h3>3. Passive Aggressive Classifier</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmoBJrAa0BKG",
        "outputId": "42acd4e5-81b9-4b9d-92fc-30c1aee2c8ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97        38\n",
            "           1       0.97      0.98      0.97        92\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       1.00      0.98      0.99       100\n",
            "           4       1.00      1.00      1.00        48\n",
            "           5       1.00      1.00      1.00        33\n",
            "           6       1.00      0.99      0.99       313\n",
            "           7       0.76      1.00      0.86        66\n",
            "           8       1.00      0.91      0.95        11\n",
            "           9       1.00      0.97      0.99       153\n",
            "          10       1.00      0.88      0.94        42\n",
            "          11       1.00      0.97      0.98        29\n",
            "          12       0.98      0.97      0.98        65\n",
            "          13       0.95      0.95      0.95        40\n",
            "          14       1.00      0.97      0.99        68\n",
            "          15       0.96      0.96      0.96        45\n",
            "          16       1.00      0.96      0.98        23\n",
            "          17       0.99      1.00      0.99        79\n",
            "          18       0.91      0.77      0.83        13\n",
            "          19       1.00      0.84      0.92        32\n",
            "          20       1.00      0.97      0.99        40\n",
            "          21       1.00      0.98      0.99       101\n",
            "          22       0.97      0.97      0.97        65\n",
            "          23       1.00      1.00      1.00         3\n",
            "          24       1.00      1.00      1.00        20\n",
            "          25       0.98      0.90      0.94        50\n",
            "          26       0.96      0.96      0.96        24\n",
            "          27       0.99      0.97      0.98       191\n",
            "          28       0.95      0.99      0.97       139\n",
            "          29       0.96      0.96      0.96        28\n",
            "          30       1.00      0.94      0.97        31\n",
            "          31       1.00      1.00      1.00         1\n",
            "          32       1.00      0.71      0.83         7\n",
            "          33       0.95      1.00      0.98        59\n",
            "          34       1.00      0.87      0.93        31\n",
            "          35       1.00      0.92      0.96       100\n",
            "          36       1.00      0.92      0.96        12\n",
            "          37       1.00      1.00      1.00         9\n",
            "          38       1.00      0.96      0.98        81\n",
            "          39       1.00      1.00      1.00        10\n",
            "          40       1.00      0.75      0.86         8\n",
            "          41       1.00      0.97      0.99        35\n",
            "          42       0.71      0.71      0.71         7\n",
            "          43       1.00      1.00      1.00         7\n",
            "          44       1.00      1.00      1.00        13\n",
            "          45       0.98      0.99      0.99       100\n",
            "          46       0.92      0.96      0.94        25\n",
            "          47       0.70      0.93      0.80        15\n",
            "          48       1.00      0.40      0.57         5\n",
            "          49       1.00      0.97      0.99        40\n",
            "          50       1.00      0.98      0.99        44\n",
            "          51       1.00      0.82      0.90        11\n",
            "          52       1.00      0.75      0.86         8\n",
            "          53       1.00      1.00      1.00        40\n",
            "          54       1.00      1.00      1.00        24\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       0.88      1.00      0.93         7\n",
            "          57       0.88      0.94      0.91       102\n",
            "          58       1.00      0.96      0.98        25\n",
            "          59       1.00      0.96      0.98        23\n",
            "          60       0.99      0.99      0.99        97\n",
            "          61       1.00      0.67      0.80         6\n",
            "          62       0.87      1.00      0.93       251\n",
            "          63       1.00      0.86      0.92         7\n",
            "          64       0.95      1.00      0.98        83\n",
            "          65       1.00      0.95      0.97        20\n",
            "          66       0.95      0.99      0.97        74\n",
            "          67       1.00      0.96      0.98        24\n",
            "          68       1.00      1.00      1.00         4\n",
            "          69       1.00      0.98      0.99       107\n",
            "          70       1.00      1.00      1.00        71\n",
            "          71       0.97      0.82      0.89        76\n",
            "          72       1.00      0.96      0.98        51\n",
            "          73       0.83      0.88      0.86        17\n",
            "          74       1.00      1.00      1.00        38\n",
            "          75       1.00      0.93      0.96        29\n",
            "          76       1.00      1.00      1.00        30\n",
            "          77       1.00      1.00      1.00        19\n",
            "          78       0.98      1.00      0.99       104\n",
            "\n",
            "    accuracy                           0.97      3961\n",
            "   macro avg       0.97      0.94      0.95      3961\n",
            "weighted avg       0.97      0.97      0.97      3961\n",
            "\n",
            "[[ 36   0   0 ...   0   0   0]\n",
            " [  0  90   0 ...   0   0   0]\n",
            " [  0   0  13 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...  30   0   0]\n",
            " [  0   0   0 ...   0  19   0]\n",
            " [  0   0   0 ...   0   0 104]]\n"
          ]
        }
      ],
      "source": [
        "PAC=PassiveAggressiveClassifier()\n",
        "PAC.fit(X,df['Labels'])\n",
        "Y3=model_Evaluate(PAC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8jyVv0P0BKG"
      },
      "source": [
        "<h3>Accuracy Metrics</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHllbIEe0BKG"
      },
      "outputs": [],
      "source": [
        "J3=jaccard_similarity_score(df['Labels'],Y3)\n",
        "FS3=f1_score(df['Labels'],Y3,average='weighted')\n",
        "Acc3=metrics.accuracy_score(df['Labels'],Y3)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UAL66Sf0BKH"
      },
      "source": [
        "<h3>4. K-Nearest Neighbors</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cDslazT0BKH"
      },
      "source": [
        "<h4>Selecting best K value</h4> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4JBi5dc0BKH",
        "outputId": "3a88c17b-a695-4a4b-ac53-578c32d488cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.96667508 0.38677102 0.14440798 0.2557435  0.20600858 0.17520828\n",
            " 0.15829336 0.14617521 0.1350669  0.12320121 0.11941429 0.11285029\n",
            " 0.1075486  0.10376168 0.09921737 0.09845998 0.09745014 0.09492552\n",
            " 0.09568291]\n",
            "[0.00285182 0.00773813 0.00558504 0.00693204 0.00642611 0.00604014\n",
            " 0.00579975 0.00561331 0.00543079 0.00522222 0.00515242 0.00502745\n",
            " 0.00492257 0.00484538 0.00475009 0.00473391 0.00471221 0.00465727\n",
            " 0.00467385]\n"
          ]
        }
      ],
      "source": [
        "Ks=20\n",
        "mean_acc1=np.zeros((Ks-1))\n",
        "std_acc1=np.zeros((Ks-1))\n",
        "for n in range(1,Ks):\n",
        "    neigh=KNeighborsClassifier(n_neighbors=n).fit(X,df['Labels'])\n",
        "    Y4=neigh.predict(X)\n",
        "    mean_acc1[n-1]=metrics.accuracy_score(df['Labels'],Y4)\n",
        "    std_acc1[n-1]=np.std(Y4==df['Labels'])/np.sqrt(Y4.shape[0])\n",
        "print(mean_acc1)\n",
        "print(std_acc1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7PkMiNP0BKH",
        "outputId": "4aa4185a-13a8-4037-abad-946082ef085f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        38\n",
            "           1       1.00      0.97      0.98        92\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       0.95      0.99      0.97       100\n",
            "           4       1.00      1.00      1.00        48\n",
            "           5       1.00      1.00      1.00        33\n",
            "           6       0.99      0.99      0.99       313\n",
            "           7       1.00      0.97      0.98        66\n",
            "           8       1.00      0.91      0.95        11\n",
            "           9       1.00      0.97      0.99       153\n",
            "          10       0.95      0.98      0.96        42\n",
            "          11       1.00      0.97      0.98        29\n",
            "          12       1.00      0.95      0.98        65\n",
            "          13       0.95      0.95      0.95        40\n",
            "          14       0.99      0.99      0.99        68\n",
            "          15       0.54      1.00      0.70        45\n",
            "          16       0.92      1.00      0.96        23\n",
            "          17       1.00      0.99      0.99        79\n",
            "          18       1.00      0.69      0.82        13\n",
            "          19       0.90      0.88      0.89        32\n",
            "          20       1.00      0.97      0.99        40\n",
            "          21       1.00      0.98      0.99       101\n",
            "          22       0.94      1.00      0.97        65\n",
            "          23       1.00      1.00      1.00         3\n",
            "          24       1.00      1.00      1.00        20\n",
            "          25       1.00      0.88      0.94        50\n",
            "          26       1.00      0.92      0.96        24\n",
            "          27       1.00      0.97      0.98       191\n",
            "          28       0.99      0.98      0.99       139\n",
            "          29       1.00      0.93      0.96        28\n",
            "          30       1.00      0.94      0.97        31\n",
            "          31       1.00      1.00      1.00         1\n",
            "          32       1.00      0.71      0.83         7\n",
            "          33       1.00      0.98      0.99        59\n",
            "          34       0.89      1.00      0.94        31\n",
            "          35       0.97      0.94      0.95       100\n",
            "          36       1.00      0.92      0.96        12\n",
            "          37       1.00      1.00      1.00         9\n",
            "          38       1.00      0.96      0.98        81\n",
            "          39       1.00      1.00      1.00        10\n",
            "          40       1.00      0.75      0.86         8\n",
            "          41       0.97      1.00      0.99        35\n",
            "          42       1.00      0.57      0.73         7\n",
            "          43       1.00      1.00      1.00         7\n",
            "          44       1.00      1.00      1.00        13\n",
            "          45       1.00      0.96      0.98       100\n",
            "          46       1.00      0.92      0.96        25\n",
            "          47       1.00      0.87      0.93        15\n",
            "          48       1.00      0.40      0.57         5\n",
            "          49       1.00      0.97      0.99        40\n",
            "          50       1.00      0.98      0.99        44\n",
            "          51       1.00      0.82      0.90        11\n",
            "          52       0.78      0.88      0.82         8\n",
            "          53       1.00      1.00      1.00        40\n",
            "          54       1.00      1.00      1.00        24\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       0.88      1.00      0.93         7\n",
            "          57       0.87      0.97      0.92       102\n",
            "          58       1.00      0.96      0.98        25\n",
            "          59       1.00      0.96      0.98        23\n",
            "          60       1.00      0.95      0.97        97\n",
            "          61       1.00      0.67      0.80         6\n",
            "          62       1.00      1.00      1.00       251\n",
            "          63       1.00      0.86      0.92         7\n",
            "          64       1.00      0.99      0.99        83\n",
            "          65       1.00      0.95      0.97        20\n",
            "          66       1.00      0.91      0.95        74\n",
            "          67       0.80      1.00      0.89        24\n",
            "          68       1.00      1.00      1.00         4\n",
            "          69       0.96      0.99      0.98       107\n",
            "          70       1.00      1.00      1.00        71\n",
            "          71       1.00      0.80      0.89        76\n",
            "          72       1.00      0.96      0.98        51\n",
            "          73       0.77      1.00      0.87        17\n",
            "          74       1.00      1.00      1.00        38\n",
            "          75       0.53      1.00      0.69        29\n",
            "          76       1.00      1.00      1.00        30\n",
            "          77       1.00      1.00      1.00        19\n",
            "          78       0.99      0.99      0.99       104\n",
            "\n",
            "    accuracy                           0.97      3961\n",
            "   macro avg       0.97      0.94      0.95      3961\n",
            "weighted avg       0.98      0.97      0.97      3961\n",
            "\n",
            "[[ 37   0   0 ...   0   0   0]\n",
            " [  0  89   0 ...   0   0   0]\n",
            " [  0   0  13 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...  30   0   0]\n",
            " [  0   0   0 ...   0  19   0]\n",
            " [  0   0   0 ...   0   0 103]]\n"
          ]
        }
      ],
      "source": [
        "neigh=KNeighborsClassifier(n_neighbors=1).fit(X,df['Labels'])\n",
        "Y4=model_Evaluate(neigh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5YnYEKh0BKH"
      },
      "source": [
        "<h3>Accuracy Metrics</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MKML8uu0BKI",
        "outputId": "e314b540-e288-4073-a05d-bd32c77fa86a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "J4=jaccard_similarity_score(df['Labels'],Y4)\n",
        "FS4=f1_score(df['Labels'],Y4,average='weighted')\n",
        "Acc4=metrics.accuracy_score(df['Labels'],Y4)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP4nBsDa0BKI"
      },
      "source": [
        "<h3>5. Multinomial Naive Bayes</h3> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqr5iAgk0BKI",
        "outputId": "13452e06-aebd-4c34-9e00-87d4f6403f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96        38\n",
            "           1       1.00      0.97      0.98        92\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       1.00      0.97      0.98       100\n",
            "           4       1.00      1.00      1.00        48\n",
            "           5       1.00      0.97      0.98        33\n",
            "           6       0.86      1.00      0.92       313\n",
            "           7       1.00      0.97      0.98        66\n",
            "           8       1.00      0.91      0.95        11\n",
            "           9       0.99      0.97      0.98       153\n",
            "          10       1.00      0.88      0.94        42\n",
            "          11       1.00      0.97      0.98        29\n",
            "          12       0.98      0.97      0.98        65\n",
            "          13       1.00      0.90      0.95        40\n",
            "          14       1.00      0.97      0.99        68\n",
            "          15       1.00      0.93      0.97        45\n",
            "          16       1.00      0.96      0.98        23\n",
            "          17       0.99      1.00      0.99        79\n",
            "          18       1.00      0.62      0.76        13\n",
            "          19       1.00      0.81      0.90        32\n",
            "          20       1.00      0.97      0.99        40\n",
            "          21       0.95      1.00      0.98       101\n",
            "          22       0.96      0.98      0.97        65\n",
            "          23       1.00      1.00      1.00         3\n",
            "          24       1.00      1.00      1.00        20\n",
            "          25       1.00      0.86      0.92        50\n",
            "          26       1.00      0.92      0.96        24\n",
            "          27       0.94      0.98      0.96       191\n",
            "          28       0.99      0.97      0.98       139\n",
            "          29       0.57      1.00      0.73        28\n",
            "          30       1.00      0.87      0.93        31\n",
            "          31       1.00      1.00      1.00         1\n",
            "          32       1.00      0.71      0.83         7\n",
            "          33       0.94      1.00      0.97        59\n",
            "          34       1.00      0.87      0.93        31\n",
            "          35       0.99      0.92      0.95       100\n",
            "          36       1.00      0.92      0.96        12\n",
            "          37       1.00      1.00      1.00         9\n",
            "          38       1.00      0.96      0.98        81\n",
            "          39       1.00      1.00      1.00        10\n",
            "          40       1.00      0.75      0.86         8\n",
            "          41       1.00      0.97      0.99        35\n",
            "          42       1.00      0.57      0.73         7\n",
            "          43       1.00      1.00      1.00         7\n",
            "          44       1.00      1.00      1.00        13\n",
            "          45       1.00      0.96      0.98       100\n",
            "          46       0.92      0.92      0.92        25\n",
            "          47       1.00      0.80      0.89        15\n",
            "          48       1.00      0.40      0.57         5\n",
            "          49       1.00      0.97      0.99        40\n",
            "          50       1.00      0.98      0.99        44\n",
            "          51       1.00      0.82      0.90        11\n",
            "          52       0.78      0.88      0.82         8\n",
            "          53       1.00      1.00      1.00        40\n",
            "          54       1.00      0.96      0.98        24\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       1.00      0.86      0.92         7\n",
            "          57       0.85      0.96      0.90       102\n",
            "          58       1.00      0.96      0.98        25\n",
            "          59       1.00      0.91      0.95        23\n",
            "          60       0.99      0.99      0.99        97\n",
            "          61       1.00      0.67      0.80         6\n",
            "          62       0.98      1.00      0.99       251\n",
            "          63       1.00      0.86      0.92         7\n",
            "          64       0.95      1.00      0.98        83\n",
            "          65       1.00      0.95      0.97        20\n",
            "          66       0.89      0.97      0.93        74\n",
            "          67       0.80      1.00      0.89        24\n",
            "          68       1.00      1.00      1.00         4\n",
            "          69       0.97      0.99      0.98       107\n",
            "          70       1.00      0.97      0.99        71\n",
            "          71       1.00      0.78      0.87        76\n",
            "          72       1.00      0.96      0.98        51\n",
            "          73       0.88      0.82      0.85        17\n",
            "          74       1.00      1.00      1.00        38\n",
            "          75       1.00      0.90      0.95        29\n",
            "          76       1.00      1.00      1.00        30\n",
            "          77       1.00      1.00      1.00        19\n",
            "          78       0.98      0.97      0.98       104\n",
            "\n",
            "    accuracy                           0.96      3961\n",
            "   macro avg       0.98      0.93      0.94      3961\n",
            "weighted avg       0.97      0.96      0.96      3961\n",
            "\n",
            "[[ 37   0   0 ...   0   0   0]\n",
            " [  0  89   0 ...   0   0   0]\n",
            " [  0   0  13 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...  30   0   0]\n",
            " [  0   0   0 ...   0  19   0]\n",
            " [  0   0   0 ...   0   0 101]]\n"
          ]
        }
      ],
      "source": [
        "MNB=MultinomialNB(alpha=0.01)\n",
        "MNB.fit(X,df['Labels'])\n",
        "Y5=model_Evaluate(MNB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_O7T2tF0BKI"
      },
      "source": [
        "<h3>Accuracy Metrics</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX6CiW6L0BKI",
        "outputId": "5e369c90-1107-4346-cc57-d3fb43291a94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "J5=jaccard_similarity_score(df['Labels'],Y5)\n",
        "FS5=f1_score(df['Labels'],Y5,average='weighted')\n",
        "Acc5=metrics.accuracy_score(df['Labels'],Y5)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRed8l0c0BKI"
      },
      "source": [
        "<h3>6. Decision Tree</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHg_Aeyg0BKJ"
      },
      "source": [
        "<h4>Selecting best depth</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0r6JT5l0BKJ",
        "outputId": "5ed509ea-f8af-4ee8-cff8-8f43369a16e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.08861399 0.11966675 0.13632921 0.16233274 0.17924766 0.21282504\n",
            " 0.24943196 0.28225196 0.32668518 0.36758394 0.41858117 0.46276193\n",
            " 0.51224438 0.55894976 0.60716991 0.65160313 0.6904822  0.73794496\n",
            " 0.78187326 0.82479172 0.86038879 0.88714971 0.90103509 0.91062863\n",
            " 0.91769755 0.9232517  0.92729109 0.92830093 0.92905832 0.93057309\n",
            " 0.93133047 0.93158293 0.93284524 0.93461247 0.93562232 0.93688463\n",
            " 0.93738955 0.93814693 0.93839939 0.93865186 0.93890432 0.9396617\n",
            " 0.93991416 0.94041909 0.94142893 0.94243878 0.94319616 0.94344862\n",
            " 0.94395355]\n",
            "[0.00451544 0.00515713 0.00545213 0.00585917 0.00609439 0.00650346\n",
            " 0.00687494 0.00715158 0.00745197 0.00766086 0.00783848 0.00792245\n",
            " 0.00794214 0.00788911 0.00775988 0.00757053 0.00734542 0.00698724\n",
            " 0.00656176 0.00604014 0.00550687 0.00502745 0.0047447  0.00453281\n",
            " 0.0043667  0.00422953 0.00412572 0.0040992  0.00407915 0.00403865\n",
            " 0.0040182  0.00401135 0.00397686 0.0039279  0.00389956 0.00386374\n",
            " 0.00384929 0.00382749 0.00382018 0.00381286 0.00380552 0.00378338\n",
            " 0.00377596 0.00376107 0.00373107 0.00370074 0.00367779 0.0036701\n",
            " 0.00365466]\n"
          ]
        }
      ],
      "source": [
        "k=50\n",
        "mean_acc3=np.zeros((k-1))\n",
        "std_acc3=np.zeros((k-1))\n",
        "for n in range(1,k):\n",
        "    Tree=DecisionTreeClassifier(criterion='entropy',max_depth=n)\n",
        "    Tree.fit(X,df['Labels'])\n",
        "    Y=Tree.predict(X)\n",
        "    mean_acc3[n-1]=metrics.accuracy_score(df['Labels'],Y)\n",
        "    std_acc3[n-1]=np.std(Y==df['Labels'])/np.sqrt(Y.shape[0])\n",
        "print(mean_acc3)\n",
        "print(std_acc3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDiqMhWF0BKJ",
        "outputId": "fb3ef1ff-6d5d-47c3-81e7-f8a2eab498f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        38\n",
            "           1       0.97      0.92      0.94        92\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.95      0.97      0.96       100\n",
            "           4       1.00      0.98      0.99        48\n",
            "           5       1.00      0.97      0.98        33\n",
            "           6       1.00      0.97      0.99       313\n",
            "           7       1.00      0.97      0.98        66\n",
            "           8       0.85      1.00      0.92        11\n",
            "           9       1.00      0.97      0.99       153\n",
            "          10       0.95      0.98      0.96        42\n",
            "          11       1.00      0.93      0.96        29\n",
            "          12       0.98      0.97      0.98        65\n",
            "          13       0.95      0.95      0.95        40\n",
            "          14       1.00      0.94      0.97        68\n",
            "          15       1.00      0.89      0.94        45\n",
            "          16       1.00      0.96      0.98        23\n",
            "          17       0.99      0.97      0.98        79\n",
            "          18       0.67      0.62      0.64        13\n",
            "          19       1.00      0.81      0.90        32\n",
            "          20       1.00      0.97      0.99        40\n",
            "          21       0.99      0.99      0.99       101\n",
            "          22       0.96      0.77      0.85        65\n",
            "          23       1.00      1.00      1.00         3\n",
            "          24       1.00      1.00      1.00        20\n",
            "          25       0.98      0.84      0.90        50\n",
            "          26       1.00      0.92      0.96        24\n",
            "          27       0.99      0.93      0.96       191\n",
            "          28       1.00      0.95      0.97       139\n",
            "          29       1.00      0.93      0.96        28\n",
            "          30       1.00      0.71      0.83        31\n",
            "          31       1.00      1.00      1.00         1\n",
            "          32       0.50      0.86      0.63         7\n",
            "          33       1.00      0.97      0.98        59\n",
            "          34       0.89      1.00      0.94        31\n",
            "          35       1.00      0.86      0.92       100\n",
            "          36       1.00      0.92      0.96        12\n",
            "          37       1.00      1.00      1.00         9\n",
            "          38       1.00      0.94      0.97        81\n",
            "          39       1.00      1.00      1.00        10\n",
            "          40       1.00      0.75      0.86         8\n",
            "          41       1.00      0.97      0.99        35\n",
            "          42       0.25      1.00      0.40         7\n",
            "          43       1.00      1.00      1.00         7\n",
            "          44       1.00      1.00      1.00        13\n",
            "          45       0.98      0.98      0.98       100\n",
            "          46       1.00      0.88      0.94        25\n",
            "          47       1.00      0.87      0.93        15\n",
            "          48       1.00      0.40      0.57         5\n",
            "          49       1.00      0.97      0.99        40\n",
            "          50       1.00      0.98      0.99        44\n",
            "          51       1.00      0.82      0.90        11\n",
            "          52       1.00      0.75      0.86         8\n",
            "          53       1.00      1.00      1.00        40\n",
            "          54       1.00      0.96      0.98        24\n",
            "          55       1.00      1.00      1.00         9\n",
            "          56       1.00      0.86      0.92         7\n",
            "          57       0.87      0.95      0.91       102\n",
            "          58       1.00      0.92      0.96        25\n",
            "          59       1.00      0.87      0.93        23\n",
            "          60       0.99      0.98      0.98        97\n",
            "          61       1.00      0.67      0.80         6\n",
            "          62       0.64      1.00      0.78       251\n",
            "          63       1.00      0.86      0.92         7\n",
            "          64       1.00      0.99      0.99        83\n",
            "          65       1.00      0.95      0.97        20\n",
            "          66       0.99      0.97      0.98        74\n",
            "          67       1.00      0.96      0.98        24\n",
            "          68       1.00      1.00      1.00         4\n",
            "          69       1.00      0.96      0.98       107\n",
            "          70       1.00      0.99      0.99        71\n",
            "          71       1.00      0.79      0.88        76\n",
            "          72       1.00      0.94      0.97        51\n",
            "          73       1.00      0.71      0.83        17\n",
            "          74       1.00      0.97      0.99        38\n",
            "          75       1.00      0.90      0.95        29\n",
            "          76       1.00      0.93      0.97        30\n",
            "          77       1.00      0.95      0.97        19\n",
            "          78       1.00      0.95      0.98       104\n",
            "\n",
            "    accuracy                           0.94      3961\n",
            "   macro avg       0.97      0.92      0.93      3961\n",
            "weighted avg       0.96      0.94      0.95      3961\n",
            "\n",
            "[[38  0  0 ...  0  0  0]\n",
            " [ 0 85  0 ...  0  0  0]\n",
            " [ 0  0 12 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 28  0  0]\n",
            " [ 0  0  0 ...  0 18  0]\n",
            " [ 0  0  0 ...  0  0 99]]\n"
          ]
        }
      ],
      "source": [
        "Tree=DecisionTreeClassifier(criterion='entropy',max_depth=50)\n",
        "Tree.fit(X,df['Labels'])\n",
        "Y6=model_Evaluate(Tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tx8jqqm0BKJ"
      },
      "source": [
        "<h3>Accuracy Metrics</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOUIyXoC0BKJ",
        "outputId": "e508b21e-c6ac-4a29-deec-ad68c2fd8811"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "J6=jaccard_similarity_score(df['Labels'],Y6)\n",
        "FS6=f1_score(df['Labels'],Y6,average='weighted')\n",
        "Acc6=metrics.accuracy_score(df['Labels'],Y6)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B7Bl83h0BKJ"
      },
      "source": [
        "<h2>Train-Set Performance</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ME0oFdw0BKK",
        "outputId": "964c2683-d52d-48f0-c20e-f4781f3fe011"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy (%)</th>\n",
              "      <th>Jaccard Index</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bernoulli Naive Bayes</th>\n",
              "      <td>86.87</td>\n",
              "      <td>0.868720</td>\n",
              "      <td>0.878655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <td>96.72</td>\n",
              "      <td>0.967180</td>\n",
              "      <td>0.968658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Passive Aggressive Classifier</th>\n",
              "      <td>96.72</td>\n",
              "      <td>0.967180</td>\n",
              "      <td>0.967327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K-Nearest Neighbors</th>\n",
              "      <td>96.67</td>\n",
              "      <td>0.966675</td>\n",
              "      <td>0.968565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Multinomial Naive Bayes</th>\n",
              "      <td>96.06</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>0.960877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>94.45</td>\n",
              "      <td>0.944458</td>\n",
              "      <td>0.948486</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Accuracy (%)  Jaccard Index  F1-Score\n",
              "Model                                                               \n",
              "Bernoulli Naive Bayes                 86.87       0.868720  0.878655\n",
              "Support Vector Machine                96.72       0.967180  0.968658\n",
              "Passive Aggressive Classifier         96.72       0.967180  0.967327\n",
              "K-Nearest Neighbors                   96.67       0.966675  0.968565\n",
              "Multinomial Naive Bayes               96.06       0.960616  0.960877\n",
              "Decision Tree                         94.45       0.944458  0.948486"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "per={'Model':['Bernoulli Naive Bayes','Support Vector Machine','Passive Aggressive Classifier','K-Nearest Neighbors',\n",
        "     'Multinomial Naive Bayes','Decision Tree'],'Accuracy (%)':[round(Acc1,2),round(Acc2,2),round(Acc3,2),round(Acc4,2),\n",
        "      round(Acc5,2),round(Acc6,2)],\n",
        "     'Jaccard Index':[J1,J2,J3,J4,J5,J6],'F1-Score':[FS1,FS2,FS3,FS4,FS5,FS6]}\n",
        "Per=pd.DataFrame(data=per)\n",
        "Per.set_index('Model',inplace=True)\n",
        "Per"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbEVPTMy0BKK"
      },
      "source": [
        "<p>Since the <b>SVM</b> model shows the best results, we choose it for predicting the keywords.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMCdkQkU0BKK"
      },
      "source": [
        "<h2>Prediction</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbStvy2V0BKK",
        "outputId": "2a23db81-850c-426a-ec4b-b7c308909019"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P. Venkatarama Reddi, J.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1. The opinion recorded by the Kerala High Cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Whether on the facts and in the circumstances...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The High Court accepted the view of the Tribun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2. The facts in brief are: The respondent-asse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3. On further appeal by the assessee, the Trib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4. It may be noted that the provision was made...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5. The learned senior counsel appearing for th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6. The decision of this Court in Commissioner ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7. For the reasons aforesaid, we affirm the op...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                File\n",
              "0                           P. Venkatarama Reddi, J.\n",
              "1  1. The opinion recorded by the Kerala High Cou...\n",
              "2  \"Whether on the facts and in the circumstances...\n",
              "3  The High Court accepted the view of the Tribun...\n",
              "4  2. The facts in brief are: The respondent-asse...\n",
              "5  3. On further appeal by the assessee, the Trib...\n",
              "6  4. It may be noted that the provision was made...\n",
              "7  5. The learned senior counsel appearing for th...\n",
              "8  6. The decision of this Court in Commissioner ...\n",
              "9  7. For the reasons aforesaid, we affirm the op..."
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lst3=[]\n",
        "index=[]\n",
        "for i in range(100,201):\n",
        "    name3=\"C:\\\\Users\\\\Aayush Singhal\\\\Downloads\\\\Projects\\\\8. Law Keywords Prediction\\\\Dataset\\\\Data\\\\Test_docs\\\\case_\"+str(i)+\"_statement.txt\"\n",
        "    f3=open(name3,\"r\")\n",
        "    for x in f3:\n",
        "        x=x.replace(\"\\n\",'')\n",
        "        if len(x)>0:\n",
        "            lst3.append(x.replace('\\n',''))\n",
        "    index.append(len(lst3))\n",
        "f3.close()\n",
        "text1=pd.DataFrame(data={\"File\":lst3})\n",
        "text1.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxPRsRdE0BKK"
      },
      "source": [
        "<h3>Lemmatizing and Cleaning Sentences</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZoGW8800BKK"
      },
      "outputs": [],
      "source": [
        "new=word_clean(text1['File'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqWinXM10BKL"
      },
      "outputs": [],
      "source": [
        "X1=vectoriser.transform(new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbHzEpql0BKL",
        "outputId": "165e4a70-d015-4678-f02e-4df36d651661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4548, 108125)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWygrAzO0BKL",
        "outputId": "1e02354c-c4a6-48c5-98b7-37946c37e439"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([62, 27, 35, ..., 24, 21, 21], dtype=int64)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_hat=SVCmodel.predict(X1)\n",
        "Y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNE4Ha9J0BKL",
        "outputId": "86c612ed-157e-48df-c2e0-5555fbfc9bbf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>venkatarama reddi</td>\n",
              "      <td>Attesting Witness, Consideration, Investigatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the opinion recorded by the kerala high court ...</td>\n",
              "      <td>Acknowledgement, Assurance, Auction, Bill, Buy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>whether on the fact and in the circumstance of...</td>\n",
              "      <td>Adjudication, Administrative Power, Back Wage,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the high court accepted the view of the tribun...</td>\n",
              "      <td>Acknowledgement, Assurance, Auction, Bill, Buy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the fact in brief are the respondent assessee ...</td>\n",
              "      <td>Adjudication, Administrative Power, Back Wage,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>on further appeal by the assessee the tribunal...</td>\n",
              "      <td>Adjudication, Administrative Power, Back Wage,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>it may be noted that the provision wa made in ...</td>\n",
              "      <td>Adjudication, Administrative Power, Back Wage,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the learned senior counsel appearing for the i...</td>\n",
              "      <td>Adjudication, Administrative Power, Back Wage,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the decision of this court in commissioner of ...</td>\n",
              "      <td>Assault, Circumstantial Evidence, Corroboratio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>for the reason aforesaid we affirm the opinion...</td>\n",
              "      <td>Constitutional Validity, Defamation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                File  \\\n",
              "0                                 venkatarama reddi    \n",
              "1  the opinion recorded by the kerala high court ...   \n",
              "2  whether on the fact and in the circumstance of...   \n",
              "3  the high court accepted the view of the tribun...   \n",
              "4  the fact in brief are the respondent assessee ...   \n",
              "5  on further appeal by the assessee the tribunal...   \n",
              "6  it may be noted that the provision wa made in ...   \n",
              "7  the learned senior counsel appearing for the i...   \n",
              "8  the decision of this court in commissioner of ...   \n",
              "9  for the reason aforesaid we affirm the opinion...   \n",
              "\n",
              "                                            Keywords  \n",
              "0  Attesting Witness, Consideration, Investigatio...  \n",
              "1  Acknowledgement, Assurance, Auction, Bill, Buy...  \n",
              "2  Adjudication, Administrative Power, Back Wage,...  \n",
              "3  Acknowledgement, Assurance, Auction, Bill, Buy...  \n",
              "4  Adjudication, Administrative Power, Back Wage,...  \n",
              "5  Adjudication, Administrative Power, Back Wage,...  \n",
              "6  Adjudication, Administrative Power, Back Wage,...  \n",
              "7  Adjudication, Administrative Power, Back Wage,...  \n",
              "8  Assault, Circumstantial Evidence, Corroboratio...  \n",
              "9                Constitutional Validity, Defamation  "
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Labels=[]\n",
        "for i in Y_hat:\n",
        "    Labels.append(IDs[i])\n",
        "final={\"File\":new,\"Keywords\":Labels}\n",
        "df_final=pd.DataFrame(data=final)\n",
        "df_final.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6_ozND30BKL"
      },
      "source": [
        "<h3>Prediction for a complete statement</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz7tveW80BKL"
      },
      "source": [
        "<p>Here, we will see the maximum keywords predicted for the entire last statement,</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aeIvBua0BKL",
        "outputId": "547a539c-7ab3-4f10-a9a5-0170d31f82b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4531    having heard learned counsel appearing for the...\n",
              "4532    the secretary ministry of woman and child deve...\n",
              "4533    the secretary ministry of woman and child deve...\n",
              "4534    insofar a the website viz URL concerned it is ...\n",
              "4535    it appears that many state have prepared their...\n",
              "4536    the secretary ministry of woman and child deve...\n",
              "4537    he will also take urgent step to fill up all t...\n",
              "4538    the secretary ministry of woman and child deve...\n",
              "4539    the affidavit filed by some of the state gover...\n",
              "4540    the secretary ministry of woman and child deve...\n",
              "4541    we request the director faculty of management ...\n",
              "4542    we also find from the affidavit filed by the v...\n",
              "4543    under the circumstance we request the director...\n",
              "4544    the director of the faculty of management stud...\n",
              "4545    the secretary ministry of woman and child deve...\n",
              "4546    in compliance of this court order the chief se...\n",
              "4547    liberty to the state of tripura and chhattisga...\n",
              "Name: File, dtype: object"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final['File'][index[-2]:index[-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yVpOxbB0BKM",
        "outputId": "980aa6c6-aec7-40c9-c310-0d7a89ea0451"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Account, Auditor, Authentication, Commercial, Consent, Direction, Dispute, Due, Generating Station, National Commission, Rate, Tariff                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         8\n",
              "Account, Account Book, Accounts, Act, Amin, Any Order, Appeal, Assumption, Award, Bench, Book, Books, Case, Challenge, Civil Appeal, Civil Court, Civil Suit, Claim, Claims, Commission, Commissioner, Commissioner's Order, Concern, Conduct, Contentions, Contrary, Control, Cost, Credit, Cross                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            3\n",
              "Coastal Zone, Policy Document                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 2\n",
              "Absorption, Ad                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
              "Attesting Witness, Consideration, Investigation, Notice, Partition, Pending, Possession, Property, Right, Sale, Sale deed, Transferred                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
              "Acquisition, Advocate General, Alcoholic Liquor, Amending Act, Ancillary Matter, Animal Husbandry, Application of Article, Attorney General, Basic Feature, Concurrent Jurisdiction, Concurrent List, Confederation, Constitution of India, Constitutional Validity, Contingencies, Contract, Control of the Union, Court Fee, Declared by Parliament, Definition, Different Entries, Distribution of Legislative Power, Distribution of Power, Doctrine of Repugnancy, Duration, Emergency, Entries in the Legislative List, Exercise of Legislative Power, Existing Law, Extent of Repugnancy, Federal Court, Federalism, First Schedule, Franchise, General Principle, Harmonious Construction, Houses of Parliament, Inconsistency Between Law, Indian Independence Act, Interpretation, Judicial Authority, Jurisdiction, Law made by Parliament, Law made by the Legislature, Laws made by Parliament, Legislation, Legislative Competence, Legislative Power, Legislature of the State, Majority Judgment, Marginal Note, Mechanically Propelled Vehicle, National Interest, Parliament, Parliament to Legislate, Parliament to Regulate, Power of Legislation, Power of Parliament, Power of the State, Powers of Legislation, Principles of Interpretation, Privilege, Privy Council, Proclamation of Emergency, Recommendation, Regulation, Repeal, Repealed, Repugnancy, Requisitioning of Property, Rule Making Power, Seventh Schedule, Special Leave Petition, Special Provision, State Legislature, State List, Statutory Provision, Subject to the Provision, Taxation, Tender, Territory of India, Trade and Commerce, Under Consideration, Union List, Union Territories    1\n",
              "Allotment, Allotment Order, Allottee, Appeal, Bona Fide, Building, Case, Ceased to Occupy, Co                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
              "Name: Keywords, dtype: int64"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final['Keywords'][index[-2]:index[-1]].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0dyFUK0BKM"
      },
      "source": [
        "<h2>2. Using Deep Learning</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYyP5EMq0BKM"
      },
      "outputs": [],
      "source": [
        "emojis={':)':'smile',':-)':'smile',';d':'wink',':-E':'vampire',':(':'sad',':-(':'sad',':-<':'sad',':P':'raspberry',':O':'surprised',\n",
        "        ':-@':'shocked',':@':'shocked',':-$':'confused',':\\\\':'annoyed',':#':'mute',':X':'mute',':^)':'smile',':-&':'confused','$_$':'greedy',\n",
        "        '@@':'eyeroll',':-!':'confused',':-D':'smile',':-0':'yell','O.o':'confused','<(-_-)>':'robot','d[-_-]b':'dj',\":'-)\":'sadsmile',';)':'wink', \n",
        "        ';-)':'wink','O:-)':'angel','O*-)':'angel','(:-D': 'gossip','=^.^=':'cat'}\n",
        "stopwords=['a','about','above','after','again','ain','all','am','an','and','any','are','as','at','be','because','been','before',\n",
        "           'being','below','between','both','by','can','d','did','do','does','doing','down','during','each','few','for','from', \n",
        "           'further','had','has','have','having','he','her','here','hers','herself','him','himself','his','how','i','if','in',\n",
        "           'into','is','it','its','itself','just','ll','m','ma','me','more','most','my','myself','now','o','of','on','once',\n",
        "           'only','or','other','our','ours','ourselves','out','own','re','s','same','she','shes','should','shouldve','so','some',\n",
        "           'such','t','than','that',\"thatll\",'the','their','theirs','them','themselves','then','there','these','they','this',\n",
        "           'those','through','to','too','under','until','up','ve','very','was','we','were','what','when','where','which','while',\n",
        "           'who','whom','why','will','with','won','y','you','youd','youll','youre','youve','your','yours','yourself','yourselves']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjs3IezV0BKM"
      },
      "outputs": [],
      "source": [
        "def preprocess(textdata):\n",
        "    processedText=[]\n",
        "    wordLemm=WordNetLemmatizer()\n",
        "    urlPattern=r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "    userPattern='@[^\\s]+'\n",
        "    alphaPattern=\"[^a-zA-Z0-9]\"\n",
        "    sequencePattern=r\"(.)\\1\\1+\"\n",
        "    seqReplacePattern=r\"\\1\\1\"\n",
        "    for tweet in textdata:\n",
        "        tweet=tweet.lower()\n",
        "        tweet=re.sub(urlPattern,' URL',tweet)\n",
        "        for emoji in emojis.keys():\n",
        "            tweet=tweet.replace(emoji,\"EMOJI\"+emojis[emoji])        \n",
        "        tweet=re.sub(userPattern,' USER',tweet)        \n",
        "        tweet=re.sub(alphaPattern,\" \",tweet)\n",
        "        tweet=re.sub(sequencePattern,seqReplacePattern,tweet)\n",
        "        tweetwords=''\n",
        "        for word in tweet.split():\n",
        "            if len(word)>1:\n",
        "                word=wordLemm.lemmatize(word)\n",
        "                tweetwords+=(word+' ')\n",
        "        processedText.append(tweetwords)\n",
        "    return processedText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yRyhTNJ0BKM"
      },
      "outputs": [],
      "source": [
        "processedtext=preprocess(list(text['File']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fahhIVLW0BKM"
      },
      "outputs": [],
      "source": [
        "index=[]\n",
        "for x in range(len(processedtext)):\n",
        "    processedtext[x]=processedtext[x].strip()\n",
        "    if len(processedtext[x])==1:\n",
        "        processedtext[x]=''\n",
        "    if processedtext[x]=='':\n",
        "        index.append(x)\n",
        "text['processed']=processedtext\n",
        "text_final=text[text['processed']!='']\n",
        "text_final.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrBDt8J50BKN"
      },
      "outputs": [],
      "source": [
        "maxLen=len(max(processedtext,key=len).split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Oay0Y9y0BKN"
      },
      "outputs": [],
      "source": [
        "def convert_to_one_hot(Y,C):\n",
        "    Y=np.eye(C)[Y.values.reshape(-1)]\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaXNafCM0BKN"
      },
      "outputs": [],
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file,'r',encoding='UTF-8') as f:\n",
        "        words=set()\n",
        "        word_to_vec_map={}\n",
        "        for line in f:\n",
        "            line=line.strip().split()\n",
        "            curr_word=line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word]=np.array(line[1:],dtype=np.float64)\n",
        "        i=1\n",
        "        words_to_index={}\n",
        "        index_to_words={}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w]=i\n",
        "            index_to_words[i]=w\n",
        "            i=i+1\n",
        "    return words_to_index,index_to_words,word_to_vec_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgPI0he00BKN"
      },
      "outputs": [],
      "source": [
        "word_to_index,index_to_word,word_to_vec_map=read_glove_vecs('C:\\\\Users\\\\Aayush Singhal\\\\Documents\\\\Projects\\\\Trials\\\\glove.6B.50d.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8huQStNF0BKN"
      },
      "outputs": [],
      "source": [
        "def sentence_to_avg(sentence,word_to_vec_map):\n",
        "    words=sentence.strip().split(\" \")\n",
        "    avg=np.zeros((50,))\n",
        "    total=0\n",
        "    zrs=np.zeros((50,))\n",
        "    for w in words:\n",
        "        try:\n",
        "            total+=word_to_vec_map[w]\n",
        "        except:\n",
        "            total+=zrs\n",
        "    avg=total/len(words)\n",
        "    return avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB1Svk6p0BKN",
        "outputId": "cebaa124-4312-47ea-89b9-fae224113685"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\smile\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "text_final['Keyword_Codes']=Keyword_codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDY7KD1u0BKO"
      },
      "outputs": [],
      "source": [
        "X_train=text_final['processed']\n",
        "y_train=text_final['Keyword_Codes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTXCbGtB0BKO"
      },
      "outputs": [],
      "source": [
        "def sentences_to_indices(X,word_to_index,max_len):\n",
        "    m=X.shape[0]\n",
        "    X_indices=np.zeros((m,max_len))\n",
        "    for i in range(m):\n",
        "        sentence_words=X[i].lower().strip().split(\" \")\n",
        "        if '' in sentence_words:\n",
        "            sentence_words.remove('')\n",
        "        j=0\n",
        "        for w in sentence_words:\n",
        "            try:\n",
        "                X_indices[i,j]=word_to_index[w]\n",
        "            except:\n",
        "                pass\n",
        "            j=j+1\n",
        "    return X_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iRwXcJv0BKO"
      },
      "outputs": [],
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map,word_to_index):\n",
        "    vocab_len=len(word_to_index)+1\n",
        "    emb_dim=word_to_vec_map[\"cucumber\"].shape[0]\n",
        "    emb_matrix=np.zeros((vocab_len,emb_dim))\n",
        "    for word, idx in word_to_index.items():\n",
        "        emb_matrix[idx,:]=word_to_vec_map[word]\n",
        "    embedding_layer=Embedding(input_dim=vocab_len,output_dim=emb_dim,trainable=True)\n",
        "    embedding_layer.build((None,))\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "    return embedding_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR0ru2mY0BKO"
      },
      "outputs": [],
      "source": [
        "def SA_LSTM(input_shape,word_to_vec_map,word_to_index):\n",
        "    sentence_indices=Input(shape=input_shape,dtype='int32')\n",
        "    embedding_layer=pretrained_embedding_layer(word_to_vec_map,word_to_index)\n",
        "    embeddings=embedding_layer(sentence_indices)   \n",
        "    X=LSTM(units=128,return_sequences=True)(embeddings)\n",
        "    X=Dropout(rate=0.3)(X)\n",
        "    X=LSTM(units=128)(X)\n",
        "    X=Dropout(rate=0.3)(X)\n",
        "    X=Dense(units=80)(X)\n",
        "    X=Activation('softmax')(X)\n",
        "    model=Model(inputs=sentence_indices,outputs=X)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svmi7Wo90BKO",
        "outputId": "5f0039fb-e3a1-4b02-806c-c7dfe113e1d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 4658)              0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 4658, 50)          20000050  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 4658, 128)         91648     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4658, 128)         0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 80)                10320     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 80)                0         \n",
            "=================================================================\n",
            "Total params: 20,233,602\n",
            "Trainable params: 20,233,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=SA_LSTM((maxLen,),word_to_vec_map,word_to_index)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvsdc_Lf0BKO"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y6bBNsr0BKP"
      },
      "outputs": [],
      "source": [
        "X_train_indices=sentences_to_indices(X_train,word_to_index,maxLen)\n",
        "Y_train_oh=convert_to_one_hot(y_train,C=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Xpz7Fogi0BKP",
        "outputId": "bdfe4710-9c24-4b3c-e853-5bae05c134ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "  64/3922 [..............................] - ETA: 1:55:45 - loss: 4.3374 - accuracy: 0.031 - ETA: 1:56:30 - loss: 4.3155 - accuracy: 0.0469"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-48-71c13c9ed7b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train_oh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    182\u001b[0m                         \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                         ins_batch = slice_arrays(\n\u001b[1;32m--> 184\u001b[1;33m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0m\u001b[0;32m    185\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(X_train_indices,Y_train_oh,epochs=25,batch_size=32,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyW4bw0e0BKP"
      },
      "outputs": [],
      "source": [
        "X_test_indices=sentences_to_indices(X_test,word_to_index,max_len=maxLen)\n",
        "Y_test_oh=convert_to_one_hot(Y_test,C=3)\n",
        "loss,acc=model.evaluate(X_test_indices,Y_test_oh)\n",
        "print(\"Test accuracy= \",acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdl4P2Xe0BKP"
      },
      "outputs": [],
      "source": [
        "X_test=np.array(['not feeling happy'])\n",
        "X_test_indices=sentences_to_indices(X_test,word_to_index,maxLen)\n",
        "print(X_test[0]+' '+np.argmax(model.predict(X_test_indices)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL9yEFMo0BKP"
      },
      "source": [
        "<h1>Deep Learning Classification</h1> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s37yYsox0BKP",
        "outputId": "2f0c606d-7209-48f7-e08d-2021cea6cd1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3922, 4658)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_indices=sentences_to_indices(X_train,word_to_index,maxLen)\n",
        "X_train_indices.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMooMhsq0BKP",
        "outputId": "afd2e3ed-d1d5-4a9a-f051-9e1096dd77f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3922, 79)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train_oh=convert_to_one_hot(y_train,C=79)\n",
        "Y_train_oh.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x09fmP9o0BKQ",
        "outputId": "96ce6edd-c6db-4bef-9dfe-b2186bb00c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3922/3922 [==============================] - 3s 686us/step - loss: 4.0782 - accuracy: 0.0829\n",
            "Epoch 2/100\n",
            "3922/3922 [==============================] - 2s 606us/step - loss: 3.9432 - accuracy: 0.0946\n",
            "Epoch 3/100\n",
            "3922/3922 [==============================] - 2s 628us/step - loss: 3.9041 - accuracy: 0.09661s - loss: 3.8 - ETA: 0s - loss: 3.8885 - \n",
            "Epoch 4/100\n",
            "3922/3922 [==============================] - 2s 626us/step - loss: 3.8881 - accuracy: 0.09870s - loss: 3.8890 - accuracy: 0.09\n",
            "Epoch 5/100\n",
            "3922/3922 [==============================] - 3s 724us/step - loss: 3.8929 - accuracy: 0.1005\n",
            "Epoch 6/100\n",
            "3922/3922 [==============================] - 2s 634us/step - loss: 3.8698 - accuracy: 0.10021s - los - ETA: 0s - los\n",
            "Epoch 7/100\n",
            "3922/3922 [==============================] - 2s 633us/step - loss: 3.8648 - accuracy: 0.09990s - loss: 3.8725 \n",
            "Epoch 8/100\n",
            "3922/3922 [==============================] - 3s 638us/step - loss: 3.8609 - accuracy: 0.1020\n",
            "Epoch 9/100\n",
            "3922/3922 [==============================] - 3s 653us/step - loss: 3.8619 - accuracy: 0.09710s - loss: 3.8\n",
            "Epoch 10/100\n",
            "3922/3922 [==============================] - 3s 652us/step - loss: 3.8483 - accuracy: 0.0997\n",
            "Epoch 11/100\n",
            "3922/3922 [==============================] - 3s 679us/step - loss: 3.8414 - accuracy: 0.0954\n",
            "Epoch 12/100\n",
            "3200/3922 [=======================>......] - ETA: 0s - loss: 3.8480 - accuracy: 0.0972"
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "n_cols=X_train_indices.shape[1]\n",
        "target=Y_train_oh\n",
        "model.add(Dense(100,activation='relu',input_shape=(n_cols,)))\n",
        "model.add(Dense(100,activation='tanh'))\n",
        "model.add(Dense(100,activation='tanh'))\n",
        "model.add(Dense(79,activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train_indices,target,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ECVHjUt0BKQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Law Keyword Prediction_N277_N292.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}